import os   # To access directories
from csv import reader  # To read label data
import pickle   # To store processed data to save time
import numpy as np  # For data processing
import cv2  # To read images
from sklearn import svm     # To create the SVM model
from matplotlib import pyplot as plt    # To generate figures
from sklearn.metrics import plot_confusion_matrix   # To generate confusion matrices
from sklearn import model_selection     # To use the train test split function

# Main function called from the main file
def main(sel, model, cfm):
    if sel==0:  # User input arg 1 - Selects which mode to use: Arg1==0 creates the model to use
        print("Task B1: Face Shape Recognition")
        model = create_model()  # Create model function called to create model object with desired parameters

        return model    # Returns model object to main file
    elif sel==1:    # User input arg 1 - Arg1==1 trains the model and validates it
        directory = 'cartoon_set/'  # Directory of the dataset for training
        y_name, y_eye, y_shp, points = import_data(directory)   # Imports data from csv file as well as pickle file if found. If not, then the data is generated by this function.
        x_use = process(points)     # Data points are flattened
        x_train, x_vald, y_train, y_vald = model_selection.train_test_split(x_use, y_shp, train_size=0.8, random_state=0)   # x,y data is split with a gives percentage and seed
        print("Number of training samples: ", len(x_train))
        model = train_model(model, x_train, y_train)    # Model is trained using x and y training data
        print("Number of validation samples: ", len(x_vald))
        accuracy = test_model(model, x_vald, y_vald)    # Model is validated using x and y validation data
        print("Accuracy of validation set: ", str(accuracy), "\n")
        if cfm==1:  # Use input arg 3 - Arg1==1 plots the confusion matrix
            disp = plot_confusion_matrix(model, x_vald, y_vald, cmap=plt.cm.Blues)  # Generate confusion matrix
            print(disp.confusion_matrix)
            plt.show()

        return accuracy     # Returns the accuracy of the model using validation data to main file
    elif sel==2:    # User input arg 1 - Arg1==2 tests the model using a test set of data
        directory = 'cartoon_set_test/'     # Directory of dataset for testing
        y_name, y_eye, y_shp, points = import_data(directory)   # Imports data from csv file as well as pickle file if found. If not, then the data is generated by this function.
        x_use = process(points)     # Data points are flattened
        print("Number of test samples: ", len(y_shp))
        accuracy = test_model(model, x_use, y_shp)  # Model is tested using x and y test data
        print("Accuracy of unseen test set: ", str(accuracy), "\n")
        if cfm==1:  # Use input arg 3 - Arg1==1 plots the confusion matrix
            disp = plot_confusion_matrix(model, x_use, y_shp, cmap=plt.cm.Blues)    # Generate confusion matrix
            print(disp.confusion_matrix)
            plt.show()

        return accuracy  # Returns the accuracy of the model using test data to main file

# Creates SVM
def create_model():
    print("Creating model...")
    clf = svm.SVC(kernel='poly', degree=3, probability=True)    # Create model object using selected parameters

    return clf  # The model object is passed back to the main function

# Train SVM
def train_model(model, x_train, y_train):
    print("Training model...")
    model = model.fit(x_train, y_train)     # Model is trained using x and y train data
    print("Model training finished")

    return model    # The trained model is passed back to the main function

# Testing mdoel
def test_model(model, x_t, y_t):
    print("Testing model...")
    accuracy = model.score(x_t, y_t)    # Model is trained using x and y test data
    print("Model testing finished")

    return accuracy     # The model accuracy is passed back to the main function

# Flatten data points
def process(points):
    no_pics = len(points[0])    # Number of images
    points_sort = []    # Empty list to store flattened data
    for i in range(0, no_pics):     # For each image
        temp = []   # Empty list to store data for each image
        temp.append(points[0][i][0])    # Append the first data point
        temp.append(points[1][i][0])    # Second point
        temp.append(points[2][i][0])    # Third point
        points_sort.append(temp)    # Append flatted list of each image to main array

    return points_sort  # Return flattened data

# Imports csv data. If pickle file is available, imports data, else generates it.
def import_data(directory):
    print("Acquiring labels and slice data...")
    # Directories for each file is generated as each image is in a sub folder of cartoon_set
    full_dir = str(os.path.dirname(__file__)[:-2])+'Datasets/'+directory
    csv_src = os.path.join(full_dir, "labels.csv")
    img_src = os.path.join(full_dir, "img")

    with open(csv_src) as file:     # Opens the labels.csv file
        dat_read = list(reader(file, delimiter='\t'))   # Data is tab spaced
        labels = list(dat_read)[1:]     # Remove first element of list (headers)

    no_pics = len(labels)   # Total number of pictures
    y_name = []     # List to store the name of each picture
    y_eye = []  # List to store eye colour
    y_shp = []  # List to store face shape
    for i in range(0, no_pics):     # For each picture
        y_name.append(labels[i][3])     # Fourth element is the name
        y_eye.append(labels[i][1])  # Second element is the eye colour
        y_shp.append(int(labels[i][2]))     # Third label is the face shape

    if not os.path.isfile(full_dir+'fshp_slice.pickle'):    # If pickle data file containing face shape sample slices doesnt exist
        print("Sample data not found - generating...")
        slice_points = [[[160, 365], [250, 365]], [[130, 335], [215, 335]], [[157, 290], [173, 290]]]   # Start and end coordinates for each of the three slice samples
        no_slice = len(slice_points)    # Number of slices (3 slices)
        points = np.zeros(shape=(no_slice, no_pics, 1))     # Samples will be stored in this array
        for m in range(0, no_pics):     # For each image
            for n in range(0, no_slice):    # For each slice
                img = cv2.imread(os.path.join(img_src,y_name[m]))   # Open the image
                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Convert colour format from RGB to BGR (cv2 works in BGR)
                slice_d = slice_points[n][0][1]     # Depth of the slice
                slice_s = slice_points[n][0][0]     # Start point of the slice
                slice_e = slice_points[n][1][0]     # End point of the slice
                sample_n = img[:][slice_d]  # Sample takes entire row at depth
                sample_n = sample_n[slice_s:slice_e]    # Sample then selects start and end location within row
                avg = np.zeros(shape=(len(sample_n), 1), dtype=float)   # The average of the RGB values are taken - as black would average to a very low number
                for i in range(0, len(sample_n)):   # For each slice
                    avg[i] = np.mean(sample_n[i])   # Calculate the RGB average for each pixel in each slice
                min_val = avg.min()     # Find the darkest pixel in the slice
                pos_list = np.where(avg == min_val)     # Find the location of this minimum value
                pos_mid = pos_list[0][int(len(pos_list[0]) / 2)]    # Select the midpoint of this (as a black line has a thickness, so we select the midpoint of this line
                avg_at_pos = avg[pos_mid]   # Set the value to be evaluate to the middle of the dark region
                if avg_at_pos < 35:     # If the dark spot is below this threshold (e.g. black)
                    points[n][m] = int(pos_mid)     # The position of this minimum is recorded as a datapoint for this image, for this sample
                else:   # If the position is not black, this means there is facial hair obscuring the outline
                    if n == 0:  # For slice 1, an average of each of the face shapes is taken
                        points[n][m] = 53.4     # If facial hair is obscuring the outline at thsi slice, assign this average to the image for this slice
                    elif n == 1:    # For slice 2
                        points[n][m] = 52.0
                    elif n == 2:    # For slice 3
                        points[n][m] = 9.2
        with open(full_dir+'fshp_slice.pickle', 'wb') as f1:    # A pickle file is opened (created if it doesnt exist)
            pickle.dump(points, f1)     # Dump points data to pickle file

    with open(full_dir+'fshp_slice.pickle', 'rb') as f2:    # Open the pickle file containing the slice sample data
        points = pickle.load(f2)    # Load the file into a variable

    return y_name, y_eye, y_shp, points     # The labels, face_list and slice sample data is passed back to the main function
